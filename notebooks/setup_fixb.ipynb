{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For ResNet18 and ResNet-34\n",
    "\n",
    "| cut...          | CIFAR numel     | bits (bytes) to adress output coordinates | | CORe50 output numel | bits (bytes) to adress output coordinates |\n",
    "|-----------------|-----------------|-------------------------------------------|-|---------------------|-------------------------------------------|\n",
    "| full ResNet     | 32x32x3 =  3072 | 12 (2)                                    | | 128x128x3 = 49152   | 16 (2)                                    |\n",
    "| after Block 1   | 8x8x64  =  4096 | 12 (2)                                    | | 32x32x64  = 65536   | 16 (2)                                    |\n",
    "| after Block 2   | 4x4x128 =  2048 | 11 (2)                                    | | 16x16x128 = 32768   | 15 (2)                                    |\n",
    "| after Block 3   | 2x2x256 =  1024 | 10 (2)                                    | | 8x8x256   = 16384   | 14 (2)                                    |\n",
    "\n",
    "For ResNet 32\n",
    "\n",
    "| cut...          | CIFAR numel      |\n",
    "|-----------------|------------------|\n",
    "| full ResNet     | 32x23x3  =  3072 |\n",
    "| after Block 1   | 32x32x16 = 16384 |\n",
    "| after Block 2   | 16x16x32 =  8192 |\n",
    "| after Block 3   | 64x8x8   =  4096 |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from math import ceil, floor, log2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = 0\n",
    "FLOAT_SIZE_BYTE = 4\n",
    "UINT_SIZE_BYTE = 1\n",
    "COORDINATE_SIZE_BYTE = 2\n",
    "MEMORY_SIZE_BYTE = 1.536 * 10**6\n",
    "LOG_DIR = '/home/marwei/Code/encodedgdumb/logs/ae_setting_b'\n",
    "DATA_DIR = '/data/marwei/pytorch/'\n",
    "MAX_EPOCHS = 256\n",
    "\n",
    "DATASETS = ['CIFAR10']\n",
    "ENCODING_BLOCKS = [3]\n",
    "K_QUANTIZATION = [4]\n",
    "K_THINNING = [0.95]\n",
    "K_AE = [1, 2, 4, 8, 16]\n",
    "\n",
    "\n",
    "# QUANTIZATION_STRATEGY = 'tiny_imagenet_transfer'\n",
    "QUANTIZATION_STRATEGY = 'cifar10_transfer'\n",
    "# QUANTIZATION_STRATEGY = 'cifar100_transfer'\n",
    "\n",
    "# CONVAE_PRETRAINING_PARAMS = 'TinyImagenet'\n",
    "CONVAE_PRETRAINING_PARAMS = 'CIFAR10_01'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "import pandas as pd\n",
    "ds_info = pd.read_pickle('ds_info.pickle')\n",
    "# ds_info = pd.read_pickle('ds_info_resnet32.pickle')\n",
    "# ds_info.loc[(ds_info.index.get_level_values(0) == 'CIFAR10'), 'model'] = 'resnet'\n",
    "ds_info.loc[(ds_info.index.get_level_values(0) == 'CIFAR10'), 'model'] = 'resnet18_cifar'\n",
    "# ds_info.loc[(ds_info.index.get_level_values(0) == 'CIFAR10') & (ds_info.index.get_level_values(1)!= 0), 'encoder'] = 'cutr'\n",
    "ds_info.loc[(ds_info.index.get_level_values(0) == 'CIFAR10') & (ds_info.index.get_level_values(1)!= 0), 'encoder'] = 'cutr_cifar'\n",
    "ds_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision.models import ResNet34_Weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exps = []\n",
    "names = []"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Basecase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for this_dataset in DATASETS:\n",
    "    for this_encoding_block in ENCODING_BLOCKS:\n",
    "        output_numel = ds_info.loc[(this_dataset, this_encoding_block), 'output_numel']\n",
    "        this_model = ds_info.loc[(this_dataset, this_encoding_block), 'model']\n",
    "        if this_encoding_block == 0:\n",
    "            n_memory_samples = floor(MEMORY_SIZE_BYTE / (output_numel * UINT_SIZE_BYTE))\n",
    "            encoder_options = [\"\"]\n",
    "        else:\n",
    "            n_memory_samples = floor(MEMORY_SIZE_BYTE / (output_numel * FLOAT_SIZE_BYTE))\n",
    "            encoder_options = [\"--encoding_block\", str(this_encoding_block)]\n",
    "\n",
    "        assert(n_memory_samples < ds_info.loc[(this_dataset, this_encoding_block), 'total_dataset_size'])\n",
    "\n",
    "        n = f\"{this_dataset}_m{n_memory_samples}_{this_model}_c{this_encoding_block}_s{SEED}\"\n",
    "\n",
    "        l =  [\"python3 src/main.py\",\n",
    "            \"--dataset\", this_dataset,\n",
    "            \"--num_classes_per_task\", str(ds_info.loc[(this_dataset, this_encoding_block), 'n_classes_per_task']),\n",
    "            \"--num_tasks\", str(ds_info.loc[(this_dataset, this_encoding_block), 'n_tasks']),\n",
    "            \"--seed\", str(SEED),\n",
    "            \"--memory_size\", str(n_memory_samples),\n",
    "            \"--num_passes\", str(MAX_EPOCHS),\n",
    "            \"--sampler\", \"greedy_sampler\",\n",
    "            \"--encoder\", ds_info.loc[(this_dataset, this_encoding_block), 'encoder']] + \\\n",
    "            encoder_options + \\\n",
    "            [\"--compressor\", \"none\",\n",
    "            \"--backbone\", this_model,\n",
    "            \"--backbone_block\", str(this_encoding_block),\n",
    "            \"--data_dir\", DATA_DIR,\n",
    "            \"--log_dir\", LOG_DIR,\n",
    "            \"--exp_name\", n]\n",
    "        exps.append(\" \".join(l))\n",
    "        names.append(n)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Quantization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for this_dataset in DATASETS:\n",
    "    for this_encoding_block in ENCODING_BLOCKS:\n",
    "        output_numel = ds_info.loc[(this_dataset, this_encoding_block), 'output_numel']\n",
    "        this_model = ds_info.loc[(this_dataset, this_encoding_block), 'model']\n",
    "        for n_quantization_states in K_QUANTIZATION:\n",
    "            available_mem = MEMORY_SIZE_BYTE - n_quantization_states * FLOAT_SIZE_BYTE  # substract space for quantile centers\n",
    "            bit_for_compressed_number = ceil(log2(n_quantization_states))\n",
    "            sample_size_byte = ceil(output_numel * bit_for_compressed_number / 8)\n",
    "            n_memory_samples = floor(available_mem / sample_size_byte)\n",
    "            assert(n_memory_samples < ds_info.loc[(this_dataset, this_encoding_block), 'total_dataset_size'])\n",
    "            \n",
    "            if this_encoding_block == 0:\n",
    "                encoder_options = [\"\"]\n",
    "            else:\n",
    "                encoder_options = [\"--encoding_block\", str(this_encoding_block)]\n",
    "\n",
    "            n = f\"{this_dataset}_m{n_memory_samples}_{this_model}_c{this_encoding_block}_quantizationTransfer{n_quantization_states}_s{SEED}\"\n",
    "\n",
    "            l =  [\"python3 src/main.py\",\n",
    "                \"--dataset\", this_dataset,\n",
    "                \"--num_classes_per_task\", str(ds_info.loc[(this_dataset, this_encoding_block), 'n_classes_per_task']),\n",
    "                \"--num_tasks\", str(ds_info.loc[(this_dataset, this_encoding_block), 'n_tasks']),\n",
    "                \"--seed\", str(SEED),\n",
    "                \"--memory_size\", str(n_memory_samples),\n",
    "                \"--num_passes\", str(MAX_EPOCHS),\n",
    "                \"--sampler\", \"greedy_sampler\",\n",
    "                \"--encoder\", ds_info.loc[(this_dataset, this_encoding_block), 'encoder']] + \\\n",
    "                encoder_options + \\\n",
    "               [\"--compressor\", \"quantization\",\n",
    "                \"--n_states\", str(n_quantization_states),\n",
    "                \"--strategy\", QUANTIZATION_STRATEGY,\n",
    "                \"--backbone\", this_model,\n",
    "                \"--backbone_block\", str(this_encoding_block),\n",
    "                \"--data_dir\", DATA_DIR,\n",
    "                \"--log_dir\", LOG_DIR,\n",
    "                \"--exp_name\", n]\n",
    "            exps.append(\" \".join(l))\n",
    "            names.append(n)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Thinning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for this_dataset in DATASETS:\n",
    "    for this_encoding_block in ENCODING_BLOCKS:\n",
    "        output_numel = ds_info.loc[(this_dataset, this_encoding_block), 'output_numel']\n",
    "        this_model = ds_info.loc[(this_dataset, this_encoding_block), 'model']\n",
    "        for this_compression_factor in K_THINNING:\n",
    "            n_elements_per_sample = floor(output_numel * (1-this_compression_factor))\n",
    "            if this_encoding_block == 0:\n",
    "                sample_size_byte = n_elements_per_sample * UINT_SIZE_BYTE + n_elements_per_sample * COORDINATE_SIZE_BYTE\n",
    "                encoder_options = [\"\"]\n",
    "            else:\n",
    "                sample_size_byte = n_elements_per_sample * FLOAT_SIZE_BYTE + n_elements_per_sample * COORDINATE_SIZE_BYTE\n",
    "                encoder_options = [\"--encoding_block\", str(this_encoding_block)]\n",
    "\n",
    "            n_memory_samples = floor(MEMORY_SIZE_BYTE / sample_size_byte)\n",
    "\n",
    "            assert(n_memory_samples < ds_info.loc[(this_dataset, this_encoding_block), 'total_dataset_size'])\n",
    "            \n",
    "            n = f\"{this_dataset}_m{n_memory_samples}_{this_model}_c{this_encoding_block}_thinning{int(this_compression_factor*100)}_s{SEED}\"\n",
    "\n",
    "            l =  [\"python3 src/main.py\",\n",
    "                \"--dataset\", this_dataset,\n",
    "                \"--num_classes_per_task\", str(ds_info.loc[(this_dataset, this_encoding_block), 'n_classes_per_task']),\n",
    "                \"--num_tasks\", str(ds_info.loc[(this_dataset, this_encoding_block), 'n_tasks']),\n",
    "                \"--seed\", str(SEED),\n",
    "                \"--memory_size\", str(n_memory_samples),\n",
    "                \"--num_passes\", str(MAX_EPOCHS),\n",
    "                \"--sampler\", \"greedy_sampler\",\n",
    "                \"--encoder\", ds_info.loc[(this_dataset, this_encoding_block), 'encoder']] + \\\n",
    "                encoder_options + \\\n",
    "               [\"--compressor\", \"thinning\",\n",
    "                \"--compression_factor\", str(this_compression_factor),\n",
    "                \"--backbone\", this_model,\n",
    "                \"--backbone_block\", str(this_encoding_block),\n",
    "                \"--data_dir\", DATA_DIR,\n",
    "                \"--log_dir\", LOG_DIR,\n",
    "                \"--exp_name\", n]\n",
    "            exps.append(\" \".join(l))\n",
    "            names.append(n)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convolutional Autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "latent_spatial_sizes = {\n",
    "    0: 8*8,\n",
    "    # 1: 2*2, #this works but is not trained, size is 2x2\n",
    "    # 2: 1*1, #this works but is not trained, size is 1x1\n",
    "    2.5: None,\n",
    "    3: None,\n",
    "    3.5: None\n",
    "}\n",
    "\n",
    "# n_latent_channels: memory_for_ae_in_mb\n",
    "ae_memory_mb = {\n",
    "    1:   4524,\n",
    "    2:   5630,\n",
    "    4:   7843,\n",
    "    8:  12268,\n",
    "    16: 21118,\n",
    "}\n",
    "\n",
    "\n",
    "for this_dataset in DATASETS:\n",
    "    for this_encoding_block in ENCODING_BLOCKS:\n",
    "        this_model = ds_info.loc[(this_dataset, this_encoding_block), 'model']\n",
    "        this_latent_spatial_size = latent_spatial_sizes[this_encoding_block]\n",
    "        if this_latent_spatial_size is None:\n",
    "            print('Skipping because the spatial size in the bottleneck would be below 0')\n",
    "            continue\n",
    "        for this_latent_size in K_AE:\n",
    "            n_elements_per_sample = this_latent_spatial_size * this_latent_size\n",
    "            sample_size_byte = n_elements_per_sample * FLOAT_SIZE_BYTE\n",
    "            free_memory_for_samples = MEMORY_SIZE_BYTE - ae_memory_mb[this_latent_size]\n",
    "            n_memory_samples = floor(free_memory_for_samples / sample_size_byte)\n",
    "\n",
    "            if this_encoding_block == 0:\n",
    "                encoder_options = [\"\"]\n",
    "            else:\n",
    "                encoder_options = [\"--encoding_block\", str(this_encoding_block)]\n",
    "\n",
    "            assert(n_memory_samples < ds_info.loc[(this_dataset, this_encoding_block), 'total_dataset_size'])\n",
    "            \n",
    "            n = f\"{this_dataset}_m{n_memory_samples}_{this_model}_c{this_encoding_block}_convae{this_latent_size}_s{SEED}\"\n",
    "\n",
    "            l =  [\"python3 src/main.py\",\n",
    "                \"--dataset\", this_dataset,\n",
    "                \"--num_classes_per_task\", str(ds_info.loc[(this_dataset, this_encoding_block), 'n_classes_per_task']),\n",
    "                \"--num_tasks\", str(ds_info.loc[(this_dataset, this_encoding_block), 'n_tasks']),\n",
    "                \"--seed\", str(SEED),\n",
    "                \"--memory_size\", str(n_memory_samples),\n",
    "                \"--num_passes\", str(MAX_EPOCHS),\n",
    "                \"--sampler\", \"greedy_sampler\",\n",
    "                \"--encoder\", ds_info.loc[(this_dataset, this_encoding_block), 'encoder']] + \\\n",
    "                encoder_options + \\\n",
    "               [\"--compressor\", \"convae\",\n",
    "                \"--latent_channels\", str(this_latent_size),\n",
    "                \"--pretraining_params\", CONVAE_PRETRAINING_PARAMS,\n",
    "                \"--backbone\", this_model,\n",
    "                \"--backbone_block\", str(this_encoding_block),\n",
    "                \"--data_dir\", DATA_DIR,\n",
    "                \"--log_dir\", LOG_DIR,\n",
    "                \"--exp_name\", n]\n",
    "            exps.append(\" \".join(l))\n",
    "            names.append(n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert len(names) == len(set(names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../scripts/fixb.sh', 'w') as fp:\n",
    "    fp.write(\"\\n\".join(exps)+'\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "encodedgdumb",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
