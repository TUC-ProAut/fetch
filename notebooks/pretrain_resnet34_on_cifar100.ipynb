{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pathlib\n",
    "import torch\n",
    "import time\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torchvision.models import resnet34\n",
    "import torchvision\n",
    "import PIL.Image\n",
    "import pandas as pd\n",
    "import random\n",
    "import os\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cutmix_prob = 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# copy the function to make a standalone notebook\n",
    "def seed_everything(seed):\n",
    "    '''\n",
    "    Fixes the class-to-task assignments and most other sources of randomness, except CUDA training aspects.\n",
    "    '''\n",
    "    # Avoid all sorts of randomness for better replication\n",
    "    random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    np.random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    if torch.cuda.is_available():\n",
    "        torch.backends.cudnn.benchmark = True # An exemption for speed :P\n",
    "\n",
    "\n",
    "def rand_bbox(size, lam):\n",
    "    W = size[2]\n",
    "    H = size[3]\n",
    "    cut_rat = np.sqrt(1. - lam)\n",
    "    cut_w = int(W * cut_rat)\n",
    "    cut_h = int(H * cut_rat)\n",
    "\n",
    "    # uniform\n",
    "    cx = np.random.randint(W)\n",
    "    cy = np.random.randint(H)\n",
    "\n",
    "    bbx1 = np.clip(cx - cut_w // 2, 0, W)\n",
    "    bby1 = np.clip(cy - cut_h // 2, 0, H)\n",
    "    bbx2 = np.clip(cx + cut_w // 2, 0, W)\n",
    "    bby2 = np.clip(cy + cut_h // 2, 0, H)\n",
    "\n",
    "    return bbx1, bby1, bbx2, bby2\n",
    "\n",
    "\n",
    "def cutmix_data(x, y, alpha=1.0, cutmix_prob=0.5):\n",
    "    assert(alpha > 0)\n",
    "    # generate mixed sample\n",
    "    lam = np.random.beta(alpha, alpha)\n",
    "\n",
    "    batch_size = x.size()[0]\n",
    "    index = torch.randperm(batch_size)\n",
    "\n",
    "    if torch.cuda.is_available():\n",
    "        index = index.cuda()\n",
    "\n",
    "    y_a, y_b = y, y[index]\n",
    "    bbx1, bby1, bbx2, bby2 = rand_bbox(x.size(), lam)\n",
    "    x[:, :, bbx1:bbx2, bby1:bby2] = x[index, :, bbx1:bbx2, bby1:bby2]\n",
    "\n",
    "    # adjust lambda to exactly match pixel ratio\n",
    "    lam = 1 - ((bbx2 - bbx1) * (bby2 - bby1) / (x.size()[-1] * x.size()[-2]))\n",
    "    return x, y_a, y_b, lam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision.datasets import CIFAR100\n",
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 128\n",
    "DEVICE = 'cuda'\n",
    "DATA_DIR = pathlib.Path('.')\n",
    "BATCH_SIZE = 256\n",
    "pretraining_classes = range(50)\n",
    "seed_everything(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_transforms = torchvision.transforms.Compose([\n",
    "    torchvision.transforms.ToTensor(),\n",
    "    torchvision.transforms.Normalize((0.5071, 0.4867, 0.4408), (0.2675, 0.2565, 0.2761))\n",
    "])\n",
    "\n",
    "test_transforms = torchvision.transforms.Compose([\n",
    "    torchvision.transforms.ToTensor(),\n",
    "    torchvision.transforms.Normalize((0.5071, 0.4867, 0.4408),(0.2675, 0.2565, 0.2761))\n",
    "])\n",
    "\n",
    "\n",
    "trainset_full = CIFAR100(\n",
    "    train=True,\n",
    "    transform=train_transforms,\n",
    "    root=DATA_DIR,\n",
    "    download=True\n",
    ")\n",
    "train_subset_idxs = [i for i in range(len(trainset_full)) if trainset_full.targets[i] in pretraining_classes]\n",
    "trainset = torch.utils.data.Subset(trainset_full, train_subset_idxs)\n",
    "\n",
    "testset_full = CIFAR100(\n",
    "    train=False,\n",
    "    transform=test_transforms,\n",
    "    root=DATA_DIR,\n",
    "    download=True\n",
    ")\n",
    "test_subset_idxs = [i for i in range(len(testset_full)) if testset_full.targets[i] in pretraining_classes]\n",
    "testset = torch.utils.data.Subset(testset_full, test_subset_idxs)\n",
    "\n",
    "trainloader = DataLoader(\n",
    "    dataset=trainset,\n",
    "    shuffle=True,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    num_workers=4,\n",
    ")\n",
    "testloader = DataLoader(\n",
    "    dataset=testset,\n",
    "    shuffle=False,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    num_workers=4,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = resnet34().to(DEVICE)\n",
    "model.fc = torch.nn.Linear(in_features=512, out_features=100, device=DEVICE)\n",
    "\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(\n",
    "    model.parameters(),\n",
    "    lr=0.01,\n",
    "    momentum=0.9,\n",
    "    weight_decay=1e-4,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_model(model, dataloader, criterion, device):\n",
    "    with torch.no_grad():\n",
    "        running_loss = 0\n",
    "        running_acc = 0\n",
    "        for data, target in dataloader:\n",
    "            data = data.to(device)\n",
    "            target = target.to(device)\n",
    "            output = model(data)\n",
    "            loss = criterion(output, target)\n",
    "\n",
    "            prob = torch.nn.functional.softmax(output, dim=1)\n",
    "            pred = torch.argmax(prob, dim=1)\n",
    "            corr = torch.eq(pred, target)\n",
    "            acc = (corr*1.0).mean()\n",
    "\n",
    "            running_acc += acc.item()\n",
    "            running_loss += loss.item()\n",
    "\n",
    "    return (\n",
    "        running_acc/len(dataloader),\n",
    "        running_loss/len(dataloader),\n",
    "    )"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for data, target in trainloader:\n",
    "    assert (target<50).all().item()\n",
    "for data, target in testloader:\n",
    "    assert (target<50).all().item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "print('starting testing')\n",
    "model.eval()\n",
    "tstart = time.time()\n",
    "acc, loss = test_model(\n",
    "    model=model,\n",
    "    dataloader=testloader,\n",
    "    criterion=criterion,\n",
    "    device=DEVICE\n",
    ")\n",
    "testtimes = [time.time()-tstart]\n",
    "testlosses = [loss]\n",
    "testaccs = [acc]\n",
    "trainlosses = [loss]\n",
    "trainaccs = [0]\n",
    "traintimes = [0]\n",
    "checkpoints = []\n",
    "best_acc = 0\n",
    "print(f\"epoch {0}\\t testloss {testlosses[-1]:.4f} \\f testacc {testaccs[-1]:.4f}\\t time {testtimes[-1]:.0f} s\")\n",
    "\n",
    "# training\n",
    "for epoch in range(EPOCHS):\n",
    "    running_loss = 0\n",
    "    running_acc = 0\n",
    "    tstart = time.time()\n",
    "    model.train()\n",
    "    for data, target in trainloader:\n",
    "        data = data.to(DEVICE)\n",
    "        target = target.to(DEVICE)\n",
    "\n",
    "        do_cutmix =  np.random.rand(1) < cutmix_prob\n",
    "        if do_cutmix:\n",
    "            data, labels_a, labels_b, lam = cutmix_data(x=data, y=target, alpha=1)\n",
    "            \n",
    "\n",
    "        # output = model(embedding)\n",
    "        output = model(data)\n",
    "        \n",
    "        if do_cutmix:\n",
    "            loss = lam * criterion(output, labels_a) + (1 - lam) * criterion(output, labels_b)\n",
    "        else:\n",
    "            loss = criterion(output, target)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        prob = torch.nn.functional.softmax(output, dim=1)\n",
    "        pred = torch.argmax(prob, dim=1)\n",
    "        corr = torch.eq(pred, target)\n",
    "        acc = (corr*1.0).mean()\n",
    "        running_acc += acc.item()\n",
    "        running_loss += loss.item()\n",
    "\n",
    "    traintimes.append(time.time() - tstart)\n",
    "    trainlosses.append(running_loss / len(trainloader))\n",
    "    trainaccs.append(running_acc / len(trainloader))\n",
    "\n",
    "    print(f\"epoch {epoch+1}\\t trainloss {trainlosses[-1]:.4f} \\f trainacc {trainaccs[-1]:.4f}\\t time {traintimes[-1]:.0f} s\")\n",
    "\n",
    "    # testing\n",
    "    model.eval()\n",
    "    running_loss = 0\n",
    "    running_acc = 0\n",
    "    tstart = time.time()\n",
    "    acc, loss = test_model(\n",
    "        model=model,\n",
    "        dataloader=testloader,\n",
    "        criterion=criterion,\n",
    "        device=DEVICE\n",
    "    )\n",
    "    testtimes.append(time.time()-tstart)\n",
    "    testlosses.append(loss)\n",
    "    testaccs.append(acc)\n",
    "\n",
    "    if acc > best_acc:\n",
    "        path = f\"resnet34_cifar100_classes0to49_e{epoch+1}.pt\"\n",
    "        torch.save(model.state_dict(), path)\n",
    "        checkpoints.append(epoch+1)\n",
    "        best_acc = acc\n",
    "        print(f\"saved checkpoint: {path}\")\n",
    "\n",
    "    print(f\"epoch {epoch+1}\\t testloss {testlosses[-1]:.4f} \\t testacc {testaccs[-1]:.4f}\\t time {testtimes[-1]:.0f} s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig, (ax1, ax2) = plt.subplots(nrows=2, ncols=1, figsize=(8, 8))\n",
    "\n",
    "ax1.plot(list(range(EPOCHS+1)), trainlosses, label='train')\n",
    "ax1.plot(list(range(EPOCHS+1)), testlosses, label='test')\n",
    "ax1.legend()\n",
    "ax1.set_title('Loss')\n",
    "ax2.plot(list(range(EPOCHS+1)), trainaccs, label='train')\n",
    "ax2.plot(list(range(EPOCHS+1)), testaccs, label='test')\n",
    "ax2.legend()\n",
    "ax2.set_title('Accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig.savefig('lc.svg')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "encodedgdumb",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
