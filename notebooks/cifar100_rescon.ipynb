{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CIFAR 100 rescon\n",
    "\n",
    "We want to find out how to maximize the perforamnce given a total amount of memory. \n",
    "\n",
    "Chart Layout:\n",
    "\n",
    "* x-axis: total memory (#slots is varied)\n",
    "* y-axis: acc\n",
    "* legend: different models\n",
    "\n",
    "The following experiments might be interesting: How much do different compression techniques change the performance of the architecture?\n",
    "\n",
    "1. Baseline without compression\n",
    "2. Thinning\n",
    "3. Quantization\n",
    "4. Convolutional Autoencoding\n",
    "5. Fully Connected Autoencoding\n",
    "\n",
    "Each with ResNet-34 or CutR34(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BACKBONE_BLOCK = 3\n",
    "SEED = 0\n",
    "LOG_DIR = '/home/marwei/code/encodedgdumb/logs/cifar100_rescon'\n",
    "DATA_DIR = '/home/marwei/pytorch'\n",
    "mem_sizes = [10, 100, 1000, 10000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "def write_save(name, contents):\n",
    "    out_path = Path('..', 'scripts', name).resolve()\n",
    "    if out_path.exists():\n",
    "        print('File already exits, nothing has been overwritten')\n",
    "    else:\n",
    "        with open(out_path, 'w') as f:\n",
    "            f.write(contents)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Formulation 1: Baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exps_base = []\n",
    "for n_memory_samples in mem_sizes:\n",
    "    n_enc = f\"cifar100_m{n_memory_samples}_cutr34_{BACKBONE_BLOCK}_splitr34_{BACKBONE_BLOCK}__s{SEED}\"\n",
    "    l_enc =  [\"python3 src/main.py\",\n",
    "            \"--dataset\", \"CIFAR100\",\n",
    "            \"--num_classes_per_task\", \"5\",\n",
    "            \"--num_tasks\", \"20\",\n",
    "            \"--seed\", str(SEED),\n",
    "            \"--memory_size\", str(n_memory_samples),\n",
    "            \"--num_passes\", \"128\",\n",
    "            \"--sampler\", \"greedy_sampler\",\n",
    "            \"--encoder\", \"cutr34\",\n",
    "            \"--encoding_block\", str(BACKBONE_BLOCK),\n",
    "            \"--compressor\", \"none\",\n",
    "            \"--backbone\", \"resnet34\",\n",
    "            \"--backbone_block\", str(BACKBONE_BLOCK),\n",
    "            \"--data_dir\", DATA_DIR,\n",
    "            \"--log_dir\", LOG_DIR,\n",
    "            \"--exp_name\", n_enc]\n",
    "    exps_base.append(\" \".join(l_enc))\n",
    "\n",
    "for n_memory_samples in mem_sizes:\n",
    "    n_unenc = f\"cifar100_m{n_memory_samples}_resnet34__s{SEED}\"\n",
    "    l_unenc =  [\"python3 src/main.py\",\n",
    "                \"--dataset\", \"CIFAR100\",\n",
    "                \"--num_classes_per_task\", \"5\",\n",
    "                \"--num_tasks\", \"20\",\n",
    "                \"--seed\", str(SEED),\n",
    "                \"--memory_size\", str(n_memory_samples),\n",
    "                \"--num_passes\", \"128\",\n",
    "                \"--sampler\", \"greedy_sampler\",\n",
    "                \"--encoder\", \"none\",\n",
    "                \"--compressor\", \"none\",\n",
    "                \"--backbone\", \"resnet34\",\n",
    "                \"--backbone_block\", \"0\",\n",
    "                \"--data_dir\", DATA_DIR,\n",
    "                \"--log_dir\", LOG_DIR,\n",
    "                \"--exp_name\", n_unenc]\n",
    "    exps_base.append(\" \".join(l_unenc))\n",
    "\n",
    "write_save('cifar100_rescon_base.sh', '\\n'.join(exps_base))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Formulation 2: Thinning\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compression_factors = [0.5, 0.8, 0.9, 0.95]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exps_thinning = []\n",
    "for n_memory_samples in mem_sizes:\n",
    "    for this_compression_factor in compression_factors:\n",
    "        \n",
    "        n = f\"cifar100_m{n_memory_samples}_cutr34_{BACKBONE_BLOCK}_thinning{int(this_compression_factor*100)}_splitr34_{BACKBONE_BLOCK}__s{SEED}\"\n",
    "        l =  [\"python3 src/main.py\",\n",
    "            \"--dataset\", \"CIFAR100\",\n",
    "            \"--num_classes_per_task\", \"5\",\n",
    "            \"--num_tasks\", \"20\",\n",
    "            \"--seed\", str(SEED),\n",
    "            \"--memory_size\", str(n_memory_samples),\n",
    "            \"--num_passes\", \"128\",\n",
    "            \"--sampler\", \"greedy_sampler\",\n",
    "            \"--encoder\", \"cutr34\",\n",
    "            \"--encoding_block\", str(BACKBONE_BLOCK),\n",
    "            \"--compressor\", \"thinning\",\n",
    "            \"--compression_factor\", str(this_compression_factor),\n",
    "            \"--backbone\", \"resnet34\",\n",
    "            \"--backbone_block\", str(BACKBONE_BLOCK),\n",
    "            \"--data_dir\", DATA_DIR,\n",
    "            \"--log_dir\", LOG_DIR,\n",
    "            \"--exp_name\", n]\n",
    "        exps_thinning.append(\" \".join(l))\n",
    "\n",
    "for n_memory_samples in mem_sizes:\n",
    "    for this_compression_factor in compression_factors:\n",
    "        n = f\"cifar100_m{n_memory_samples}_thinning{int(this_compression_factor*100)}_resnet34__s{SEED}\"\n",
    "        l =  [\"python3 src/main.py\",\n",
    "            \"--dataset\", \"CIFAR100\",\n",
    "            \"--num_classes_per_task\", \"5\",\n",
    "            \"--num_tasks\", \"20\",\n",
    "            \"--seed\", str(SEED),\n",
    "            \"--memory_size\", str(n_memory_samples),\n",
    "            \"--num_passes\", \"128\",\n",
    "            \"--sampler\", \"greedy_sampler\",\n",
    "            \"--encoder\", \"none\",\n",
    "            \"--compressor\", \"thinning\",\n",
    "            \"--compression_factor\", str(this_compression_factor),\n",
    "            \"--backbone\", \"resnet34\",\n",
    "            \"--data_dir\", DATA_DIR,\n",
    "            \"--log_dir\", LOG_DIR,\n",
    "            \"--exp_name\", n]\n",
    "        exps_thinning.append(\" \".join(l))\n",
    "\n",
    "write_save('cifar100_rescon_thinning.sh', '\\n'.join(exps_thinning))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Formulation 3: Quantization\n",
    "\n",
    "We have 4 loops for all combinations:\n",
    "\n",
    "* with and without the encoder\n",
    "* with local and transfer compression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_states_list = [2, 4, 8, 16, 32]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exps_quantization = []\n",
    "\n",
    "# encoding and local quantization\n",
    "for n_memory_samples in mem_sizes:\n",
    "    for n_states in n_states_list:\n",
    "        n = f\"cifar100_m{n_memory_samples}_cutr34_{BACKBONE_BLOCK}_quantization{n_states}_splitr34_{BACKBONE_BLOCK}__s{SEED}\"\n",
    "        l =  [\"python3 src/main.py\",\n",
    "            \"--dataset\", \"CIFAR100\",\n",
    "            \"--num_classes_per_task\", \"5\",\n",
    "            \"--num_tasks\", \"20\",\n",
    "            \"--seed\", str(SEED),\n",
    "            \"--memory_size\", str(n_memory_samples),\n",
    "            \"--num_passes\", \"128\",\n",
    "            \"--sampler\", \"greedy_sampler\",\n",
    "            \"--encoder\", \"cutr34\",\n",
    "            \"--encoding_block\", str(BACKBONE_BLOCK),\n",
    "            \"--compressor\", \"quantization\",\n",
    "            \"--n_states\", str(n_states),\n",
    "            \"--backbone\", \"resnet34\",\n",
    "            \"--backbone_block\", str(BACKBONE_BLOCK),\n",
    "            \"--data_dir\", DATA_DIR,\n",
    "            \"--log_dir\", LOG_DIR,\n",
    "            \"--exp_name\", n]\n",
    "        exps_quantization.append(\" \".join(l))\n",
    "\n",
    "# no encoding and local quantization\n",
    "for n_memory_samples in mem_sizes:\n",
    "    for n_states in n_states_list:    \n",
    "        n = f\"cifar100_m{n_memory_samples}_quantization{n_states}_resnet34__s{SEED}\"\n",
    "        l =  [\"python3 src/main.py\",\n",
    "            \"--dataset\", \"CIFAR100\",\n",
    "            \"--num_classes_per_task\", \"5\",\n",
    "            \"--num_tasks\", \"20\",\n",
    "            \"--seed\", str(SEED),\n",
    "            \"--memory_size\", str(n_memory_samples),\n",
    "            \"--num_passes\", \"128\",\n",
    "            \"--sampler\", \"greedy_sampler\",\n",
    "            \"--encoder\", \"none\",\n",
    "            \"--compressor\", \"quantization\",\n",
    "            \"--n_states\", str(n_states),\n",
    "            \"--backbone\", \"resnet34\",\n",
    "            \"--data_dir\", DATA_DIR,\n",
    "            \"--log_dir\", LOG_DIR,\n",
    "            \"--exp_name\", n]\n",
    "        exps_quantization.append(\" \".join(l))\n",
    "\n",
    "# encoding and global quantization\n",
    "for n_memory_samples in mem_sizes:\n",
    "    for n_states in n_states_list:\n",
    "        n = f\"cifar100_m{n_memory_samples}_cutr34_{BACKBONE_BLOCK}_quantization{n_states}_splitr34_{BACKBONE_BLOCK}__s{SEED}_transfer\"\n",
    "        l =  [\"python3 src/main.py\",\n",
    "            \"--dataset\", \"CIFAR100\",\n",
    "            \"--num_classes_per_task\", \"5\",\n",
    "            \"--num_tasks\", \"20\",\n",
    "            \"--seed\", str(SEED),\n",
    "            \"--memory_size\", str(n_memory_samples),\n",
    "            \"--num_passes\", \"128\",\n",
    "            \"--sampler\", \"greedy_sampler\",\n",
    "            \"--encoder\", \"cutr34\",\n",
    "            \"--encoding_block\", str(BACKBONE_BLOCK),\n",
    "            \"--compressor\", \"quantization\",\n",
    "            \"--n_states\", str(n_states),\n",
    "            \"--strategy\", \"tiny_imagenet_transfer\",\n",
    "            \"--backbone\", \"resnet34\",\n",
    "            \"--backbone_block\", str(BACKBONE_BLOCK),\n",
    "            \"--data_dir\", DATA_DIR,\n",
    "            \"--log_dir\", LOG_DIR,\n",
    "            \"--exp_name\", n]\n",
    "        exps_quantization.append(\" \".join(l))\n",
    "\n",
    "# no encoding and global quantization\n",
    "for n_memory_samples in mem_sizes:\n",
    "    for n_states in n_states_list:    \n",
    "        n = f\"cifar100_m{n_memory_samples}_quantization{n_states}_resnet34__s{SEED}_transfer\"\n",
    "        l =  [\"python3 src/main.py\",\n",
    "            \"--dataset\", \"CIFAR100\",\n",
    "            \"--num_classes_per_task\", \"5\",\n",
    "            \"--num_tasks\", \"20\",\n",
    "            \"--seed\", str(SEED),\n",
    "            \"--memory_size\", str(n_memory_samples),\n",
    "            \"--num_passes\", \"128\",\n",
    "            \"--sampler\", \"greedy_sampler\",\n",
    "            \"--encoder\", \"none\",\n",
    "            \"--compressor\", \"quantization\",\n",
    "            \"--n_states\", str(n_states),\n",
    "            \"--strategy\", \"tiny_imagenet_transfer\",\n",
    "            \"--backbone\", \"resnet34\",\n",
    "            \"--data_dir\", DATA_DIR,\n",
    "            \"--log_dir\", LOG_DIR,\n",
    "            \"--exp_name\", n]\n",
    "        exps_quantization.append(\" \".join(l))\n",
    "\n",
    "write_save('cifar100_rescon_quantization.sh', '\\n'.join(exps_quantization))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Formulation 4: conv. Autoencoder\n",
    "\n",
    "We only get good performance for 2 blocks. This might be because the the size of the latent vector is to small for lager network-sizes. 2 is used as a default for all the other experiments.\n",
    "\n",
    "Also keep in mind that the conv. ae. does not work with encoded inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "AE_N_BLOCKS = 2\n",
    "latent_clannels_list = [1, 2, 4, 8, 16]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exps_autoencoder = []\n",
    "\n",
    "# without encoder\n",
    "for n_memory_samples in mem_sizes:\n",
    "    for this_latent_channels in latent_clannels_list:\n",
    "        n = f\"cifar100_m{n_memory_samples}_convae{this_latent_channels}_resnet34__s{SEED}\"\n",
    "        l =  [\"python3 src/main.py\",\n",
    "            \"--dataset\", \"CIFAR100\",\n",
    "            \"--num_classes_per_task\", \"5\",\n",
    "            \"--num_tasks\", \"20\",\n",
    "            \"--seed\", str(SEED),\n",
    "            \"--memory_size\", str(n_memory_samples),\n",
    "            \"--num_passes\", \"128\",\n",
    "            \"--sampler\", \"greedy_sampler\",\n",
    "            \"--encoder\", \"none\",\n",
    "            \"--compressor\", \"convae\",\n",
    "            \"--n_blocks\", str(AE_N_BLOCKS),\n",
    "            \"--latent_channels\", str(this_latent_channels),\n",
    "            \"--backbone\", \"resnet34\",\n",
    "            \"--data_dir\", DATA_DIR,\n",
    "            \"--log_dir\", LOG_DIR,\n",
    "            \"--exp_name\", n]\n",
    "        exps_autoencoder.append(\" \".join(l))\n",
    "\n",
    "write_save('cifar100_rescon_convae.sh', '\\n'.join(exps_autoencoder))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Formulation 5: FC Autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bottleneck_sizes = [2, 4, 8, 16, 32, 64]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exps_fcae_enc = []\n",
    "exps_fcae_none = []\n",
    "\n",
    "for n_memory_samples in mem_sizes:\n",
    "    for bottleneck_size in bottleneck_sizes:\n",
    "        l =  [\"python3 src/main.py\",\n",
    "            \"--dataset\", \"CIFAR100\",\n",
    "            \"--num_classes_per_task\", \"5\",\n",
    "            \"--num_tasks\", \"20\",\n",
    "            \"--seed\", str(SEED),\n",
    "            \"--memory_size\", str(n_memory_samples),\n",
    "            \"--num_passes\", \"128\",\n",
    "            \"--sampler\", \"greedy_sampler\",\n",
    "            \"--compressor\", \"fcae\",\n",
    "            \"--bottleneck_neurons\", str(bottleneck_size),\n",
    "            \"--data_dir\", DATA_DIR,\n",
    "            \"--log_dir\", LOG_DIR,\n",
    "        ]\n",
    "\n",
    "        n_no_enc = f\"cifar100_m{n_memory_samples}_fcae{bottleneck_size}_resnet34__s{SEED}\"\n",
    "        n_enc = f\"cifar100_m{n_memory_samples}_cutr34_{BACKBONE_BLOCK}_fcae{bottleneck_size}_resnet34__s{SEED}\"\n",
    "\n",
    "        l_no_enc = l + [\n",
    "            \"--encoder\", \"none\",\n",
    "            \"--backbone\", \"resnet34\",\n",
    "            \"--exp_name\", n_no_enc\n",
    "        ]\n",
    "        l_enc = l + [\n",
    "            \"--encoder\", \"cutr34\",\n",
    "            \"--encoding_block\", str(BACKBONE_BLOCK),\n",
    "            \"--backbone\", \"resnet34\",\n",
    "            \"--backbone_block\", str(BACKBONE_BLOCK),\n",
    "            \"--exp_name\", n_enc        \n",
    "        ]\n",
    "\n",
    "        exps_fcae_none.append(' '.join(l_no_enc))\n",
    "        exps_fcae_enc.append(' '.join(l_enc))\n",
    "exps_fcae = exps_fcae_none + exps_fcae_enc\n",
    "\n",
    "write_save('cifar100_rescon_fcae.sh', '\\n'.join(exps_fcae))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Write one file for everything"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_exps = exps_base + exps_thinning + exps_quantization + exps_autoencoder + exps_fcae\n",
    "write_save('cifar100_rescon_all.sh', '\\n'.join(all_exps))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Results\n",
    "\n",
    "CIFAR10-Dataset\n",
    "\n",
    "| cut...                    | output shape | output size | bits (bytes) to adress output coordinates |\n",
    "|---------------------------|--------------|-------------|-------------------------------------------|\n",
    "| after Block 1             | 8x8x64       |  4096       | 12 (2)                                    |\n",
    "| after Block 2             | 4x4x128      |  2048       | 11 (2)                                    |\n",
    "| after Block 3             | 2x2x256      |  1024       | 10 (2)                                    |\n",
    "| after Block 4             | 1x1x512      |   512       |  9 (2)                                    |\n",
    "\n",
    "We assume\n",
    "\n",
    "* one float takes up 4 Byte of Memory\n",
    "* uints are used for output-coordinates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "parent_dir = Path(LOG_DIR)\n",
    "MODEL_SIZE_MB = 0\n",
    "OUTPUT_SIZE_ENCODED = 1024\n",
    "OUTPUT_SIZE_UNENCODED = 32*32*3\n",
    "FLOAT_SIZE_BYTE = 4\n",
    "UINT_SIZE_BYTE = 1\n",
    "COORDINATE_SIZE_BYTE = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "log_paths = [Path(d, 'checkpoint.log') for d in parent_dir.glob('cifar100_*')]\n",
    "c = []\n",
    "\n",
    "for exp in log_paths:\n",
    "    with open(exp) as infile:\n",
    "        loglines = infile.read().splitlines()\n",
    "\n",
    "    try:\n",
    "        mem_size = int(re.findall(r\"memory_size=(\\d+)\", loglines[0])[0])\n",
    "        final_acc = float(re.findall(r\"Acc: \\[(.*?)\\]\", loglines[-1])[0])\n",
    "        compressor = re.findall(r\"compressor=\\'(.*?)\\'\", loglines[0])[0]\n",
    "        encoder = re.findall(r\"encoder=\\'(.*?)\\'\", loglines[0])[0]\n",
    "    except IndexError:\n",
    "        print(f'could not parse {exp}')\n",
    "        continue\n",
    "\n",
    "    compressor_param = None\n",
    "\n",
    "    if compressor == 'thinning':\n",
    "        compressor_param = float(re.findall(r\"compression_factor=(.*?),\", loglines[0])[0])\n",
    "        compressor_name = f'{compressor} ({compressor_param})'\n",
    "    elif compressor == 'quantization':\n",
    "        compressor_param = int(re.findall(r\"n_states=(\\d+)\", loglines[0])[0])\n",
    "        try:\n",
    "            strategy = re.findall(r\"strategy=\\'(.*?)\\'\", loglines[0])[0]\n",
    "            assert strategy == 'tiny_imagenet_transfer' or strategy == 'local'\n",
    "            if strategy == 'tiny_imagenet_transfer':\n",
    "                compressor_new = 'quantization transfer'\n",
    "            elif strategy == 'local':\n",
    "                compressor_new = 'quantization local'\n",
    "            else:\n",
    "                raise ValueError('Unknown Quantization Stragegy: ' + strategy)\n",
    "        except IndexError:\n",
    "            compressor_new = 'quantization local'\n",
    "        compressor_name = f'{compressor} ({compressor_param})'\n",
    "        compressor = compressor_new\n",
    "    elif compressor == 'fcae':\n",
    "        compressor_param = int(re.findall(r\"bottleneck_neurons=(\\d+)\", loglines[0])[0])\n",
    "        compressor_name = f'Autoencoder (FC, {compressor_param})'\n",
    "    elif compressor == 'convae':\n",
    "        compressor_param = int(re.findall(r\"latent_channels=(\\d+)\", loglines[0])[0])\n",
    "        compressor_name = f'Autoencoder (Conv., {compressor_param})'\n",
    "    elif compressor == 'none':\n",
    "        compressor_name = 'no compression'\n",
    "        compressor_param = 0\n",
    "    else:\n",
    "        raise ValueError(f'Unknown Compressor {compressor}')\n",
    "\n",
    "    if encoder == 'cutr34':\n",
    "        encoding_block = int(re.findall(r\"encoding_block=(\\d+)\", loglines[0])[0])\n",
    "        output_size = OUTPUT_SIZE_ENCODED\n",
    "        encoder_name = f'CutR34({encoding_block})'\n",
    "    elif encoder == 'none':\n",
    "        output_size = OUTPUT_SIZE_UNENCODED\n",
    "        encoder_name = 'no encoding'\n",
    "    else:\n",
    "        raise ValueError('Unknown Encoder')\n",
    "\n",
    "    c.append({\n",
    "        'mem_size': mem_size,\n",
    "        'final_acc': final_acc,\n",
    "        'output_size': output_size,\n",
    "        'encoder': encoder,\n",
    "        'encoder_name': encoder_name,\n",
    "        'compressor': compressor,\n",
    "        'compressor_name': compressor_name,\n",
    "        'compressor_param': compressor_param,\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.DataFrame.from_records(c)\n",
    "df['mem_size_mb'] = 0\n",
    "df['byte_for_datatype'] = 0\n",
    "df.loc[df['encoder']=='none', 'bytes_for_datatype'] = UINT_SIZE_BYTE\n",
    "df.loc[df['encoder']=='cutr34', 'bytes_for_datatype'] = FLOAT_SIZE_BYTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['sort_idx'] = 0\n",
    "df.loc[df.compressor=='none', 'sort_idx'] = 0\n",
    "df.loc[df.compressor=='thinning', 'sort_idx'] = 1\n",
    "df.loc[df.compressor=='quantization local', 'sort_idx'] = 2\n",
    "df.loc[df.compressor=='quantization transfer', 'sort_idx'] = 3\n",
    "df.loc[df.compressor=='fcae', 'sort_idx'] = 4\n",
    "df.loc[df.compressor=='convae', 'sort_idx'] = 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[df['compressor']=='none', 'mem_size_mb'] = \\\n",
    "    df.loc[df['compressor']=='none', 'bytes_for_datatype'] \\\n",
    "    * df.loc[df['compressor']=='none', 'output_size'] \\\n",
    "    * df.loc[df['compressor']=='none', 'mem_size'] \\\n",
    "    / (1024*1024) \\\n",
    "    + MODEL_SIZE_MB"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Thinning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['n_elements_per_sample'] = 0\n",
    "df['sample_size_byte'] = 0\n",
    "\n",
    "df.loc[df.compressor=='thinning', 'n_elements_per_sample'] = \\\n",
    "    df.loc[df.compressor=='thinning', 'output_size'] \\\n",
    "    * (1 - df.loc[df.compressor=='thinning', 'compressor_param'])\n",
    "df.loc[df.compressor=='thinning', 'sample_size_byte'] = \\\n",
    "    df.loc[df.compressor=='thinning', 'n_elements_per_sample'] \\\n",
    "    * df.loc[df.compressor=='thinning', 'bytes_for_datatype'] \\\n",
    "    + df.loc[df.compressor=='thinning', 'n_elements_per_sample'] \\\n",
    "    * COORDINATE_SIZE_BYTE\n",
    "df.loc[df.compressor=='thinning', 'mem_size_mb'] = \\\n",
    "    df.loc[df.compressor=='thinning', 'sample_size_byte'] \\\n",
    "    * df.loc[df.compressor=='thinning', 'mem_size'] \\\n",
    "    / (1024*1024) \\\n",
    "    + MODEL_SIZE_MB\n",
    "df.drop(columns=['n_elements_per_sample', 'sample_size_byte'], inplace=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Quantization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ctypes.wintypes import FLOAT\n",
    "import numpy as np\n",
    "df['compressed_data'] = 0\n",
    "df['inverval_centers'] = 0\n",
    "\n",
    "mask = (df.compressor=='quantization local') | (df.compressor=='quantization transfer')\n",
    "df.loc[mask, 'compressed_data'] = \\\n",
    "    df.loc[mask, 'mem_size'] \\\n",
    "    * np.ceil(\n",
    "        np.ceil(np.log2(df.loc[mask, 'compressor_param']))\n",
    "        * df.loc[mask, 'output_size']\n",
    "        / 8\n",
    "    )\n",
    "\n",
    "df.loc[df['compressor']=='quantization local', 'inverval_centers'] = \\\n",
    "    df.loc[df['compressor']=='quantization local', 'mem_size'] \\\n",
    "    * df.loc[df['compressor']=='quantization local', 'compressor_param'] \\\n",
    "    * FLOAT_SIZE_BYTE\n",
    "\n",
    "df.loc[df['compressor']=='quantization transfer', 'inverval_centers'] = \\\n",
    "    df.loc[df['compressor']=='quantization transfer', 'compressor_param'] \\\n",
    "    * FLOAT_SIZE_BYTE\n",
    "\n",
    "df.loc[mask, 'mem_size_mb'] = \\\n",
    "    MODEL_SIZE_MB \\\n",
    "    + (\n",
    "        df.loc[mask, 'inverval_centers']\n",
    "        + df.loc[mask, 'compressed_data']\n",
    "    ) / (8*1024*1024)\n",
    "\n",
    "df.drop(columns=['compressed_data', 'inverval_centers'], inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convolutional Autoencoder. This was only done using unencoded inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ae_size_mb = {\n",
    "    1: 0.00452423095703125,\n",
    "    2: 0.0056304931640625,\n",
    "    4: 0.007843017578125,\n",
    "    8: 0.01226806640625,\n",
    "    16: 0.0211181640625,\n",
    "}\n",
    "\n",
    "df['convae_size'] = df['compressor_param'].astype('int')\n",
    "df.loc[df['compressor']=='convae', 'convae_size'] = df.loc[df['compressor']=='convae', 'convae_size'].replace(ae_size_mb)\n",
    "df.loc[df['compressor']=='convae', 'mem_size_mb'] = \\\n",
    "    MODEL_SIZE_MB \\\n",
    "    + df.loc[df['compressor']=='convae', 'convae_size'] \\\n",
    "    + ( \n",
    "        df.loc[df['compressor']=='convae', 'mem_size']\n",
    "        * 8 * 8 * df.loc[df['compressor']=='convae', 'compressor_param']\n",
    "        * FLOAT_SIZE_BYTE\n",
    "        / (1024*1024)\n",
    "    )\n",
    "\n",
    "df.drop(columns=['convae_size'], inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fully Connected Autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SIZE_FCAE_NONE_MB = {\n",
    "    64: 52.08887481689453,\n",
    "    32: 43.0804443359375,\n",
    "    16: 36.295753479003906,\n",
    "    8: 30.972145080566406,\n",
    "    4: 26.713584899902344,\n",
    "    2: 23.205177307128906,\n",
    "}\n",
    "SIZE_FCAE_CUTR_MB = {\n",
    "    64: 8.331954956054688,\n",
    "    32: 6.5640106201171875,\n",
    "    16: 5.3397216796875,\n",
    "    8: 4.450263977050781,\n",
    "    4: 3.7687225341796875,\n",
    "    2: 3.2361679077148438,\n",
    "}\n",
    "\n",
    "df['fcae_size'] = df['compressor_param'].astype('int')\n",
    "df.loc[(df['compressor']=='fcae') & (df['encoder']=='none'), 'fcae_size'] = df.loc[(df['compressor']=='fcae') & (df['encoder']=='none'), 'fcae_size'].replace(SIZE_FCAE_NONE_MB)\n",
    "df.loc[(df['compressor']=='fcae') & (df['encoder']=='cutr34'), 'fcae_size'] = df.loc[(df['compressor']=='fcae') & (df['encoder']=='cutr34'), 'fcae_size'].replace(SIZE_FCAE_CUTR_MB)\n",
    "df.loc[df['compressor']=='fcae', 'mem_size_mb'] = \\\n",
    "    df.loc[df['compressor']=='fcae', 'fcae_size'] \\\n",
    "    + (\n",
    "        df.loc[df['compressor']=='fcae', 'mem_size']\n",
    "        * df.loc[df['compressor']=='fcae', 'compressor_param']\n",
    "        * FLOAT_SIZE_BYTE\n",
    "        / (1024*1024)\n",
    "    )\n",
    "df.drop(columns=['fcae_size'], inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.express as px\n",
    "from plot_utils import science_template\n",
    "\n",
    "config = {\n",
    "    'displaylogo': False,\n",
    "    'toImageButtonOptions': {\n",
    "        'format': 'png', # one of png, svg, jpeg, webp\n",
    "        'filename': 'rescon',\n",
    "        'scale': 3 # Multiply title/legend/axis/canvas sizes by this factor\n",
    "    }\n",
    "}\n",
    "\n",
    "fig = px.line(\n",
    "    df.sort_values(['sort_idx', 'mem_size_mb']),\n",
    "    x='mem_size_mb',\n",
    "    y='final_acc',\n",
    "    color='compressor_name',\n",
    "    facet_row='encoder_name',\n",
    "    facet_col='compressor',\n",
    "    markers=True,\n",
    "    log_x=True,\n",
    "    template=science_template,\n",
    "    title='CIFAR100',\n",
    "    hover_data={\n",
    "        'mem_size': True\n",
    "    },\n",
    "    labels={\n",
    "        'mem_size': 'Number of Memory Slots',\n",
    "        'final_acc': 'Accuracy',\n",
    "        'mem_size_mb': 'Total Storage Comsumption [MiB]',\n",
    "        'encoder_name': 'Encoder',\n",
    "        'compressor_name': 'Compression Strategy',\n",
    "        'compressor': 'Compressor',\n",
    "        'fcae': 'Fully Connected Autoencoder'\n",
    "    })\n",
    "fig.show(renderer='browser', config=config)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use Matplotlib so we have more options"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot  as plt\n",
    "\n",
    "df.sort_values(['sort_idx', 'mem_size_mb'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(nrows=2, ncols=6, figsize=(30, 7))\n",
    "fig.subplots_adjust(hspace=0.4, wspace=0.2)\n",
    "\n",
    "c_names = {\n",
    "    'thinning': 'Thinning',\n",
    "    'quantization local': 'Quantization (local)',\n",
    "    'quantization transfer': 'Quantization (transfer)',\n",
    "    'fcae': 'Fully Connected Autoencoder',\n",
    "    'convae': 'Convolutional Autoencoder',\n",
    "    'none': 'No Compression'\n",
    "}\n",
    "\n",
    "colors = [\n",
    "        '#636efa',\n",
    "        '#EF553B',\n",
    "        '#00cc96',\n",
    "        '#ab63fa',\n",
    "        '#FFA15A',\n",
    "        '#19d3f3',\n",
    "        '#FF6692',\n",
    "        '#B6E880',\n",
    "        '#FF97FF',\n",
    "        '#FECB52'\n",
    "]\n",
    "\n",
    "for i_comp, comp in enumerate(df.compressor.unique()):\n",
    "    mem_min = df.loc[df['compressor']==comp, 'mem_size_mb'].min()\n",
    "    mem_max = df.loc[df['compressor']==comp, 'mem_size_mb'].max()\n",
    "    for i_enc, enc in enumerate(df.encoder.unique()):\n",
    "        if comp == 'convae' and enc == 'cutr34':\n",
    "            axes[i_enc, i_comp].remove()\n",
    "            continue\n",
    "        compressor_params = df.loc[(df['encoder']==enc) & (df['compressor']==comp), 'compressor_param'].unique()\n",
    "        ymax = df.loc[df['encoder']==enc, 'final_acc'].max() * 1.1\n",
    "        for icp, cp in enumerate(compressor_params):\n",
    "            df.loc[(df['encoder']==enc) & (df['compressor']==comp) & (df['compressor_param']==cp)].plot(\n",
    "                x='mem_size_mb',\n",
    "                y='final_acc',\n",
    "                ax=axes[i_enc, i_comp],\n",
    "                logx=True,\n",
    "                xlim=(mem_min*0.8, mem_max*1.2),\n",
    "                ylim=(-0.03, ymax),\n",
    "                grid=True,\n",
    "                marker='o',\n",
    "                color=colors[icp]\n",
    "            )\n",
    "\n",
    "        if enc == 'none':\n",
    "            if comp == 'none':\n",
    "                title = 'GDumb'\n",
    "            else:\n",
    "                title = 'ResNet-34 + ' + c_names[comp]\n",
    "        else:\n",
    "            enc_name = df.loc[(df['encoder']==enc) & (df['compressor']==comp), 'encoder_name'].unique()[0]\n",
    "            title = f\"{enc_name} + {c_names[comp]}\"\n",
    "        axes[i_enc, i_comp].set_title(title)\n",
    "        if comp != 'thinning':\n",
    "            compressor_params = [int(x) for x in compressor_params]\n",
    "        axes[i_enc, i_comp].axhline(y=0.01, xmin=0, xmax=1, c=\"k\", linewidth=1, zorder=0, linestyle='--')\n",
    "        if (enc, comp) == ('none', 'fcae'):\n",
    "            axes[i_enc, i_comp].legend(compressor_params, loc='upper left')\n",
    "        elif (enc, comp) == ('cutr34', 'fcae'):\n",
    "            axes[i_enc, i_comp].legend(compressor_params, loc='upper right')\n",
    "        else:\n",
    "            axes[i_enc, i_comp].legend(compressor_params)\n",
    "        axes[i_enc, i_comp].set_xlabel(\"\")\n",
    "        axes[i_enc, i_comp].set_ylabel(\"\")\n",
    "        if i_comp==0:\n",
    "            axes[i_enc, i_comp].legend().remove()\n",
    "            axes[i_enc, i_comp].set_ylabel(\"Accuracy\")\n",
    "        if i_enc==1:\n",
    "            axes[i_enc, i_comp].set_xlabel(\"Memory Size [MiB]\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig.savefig('plot.pdf')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Best Performance for Memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "view = df.sort_values('mem_size_mb')\n",
    "view['method'] = df['compressor'].replace(c_names) + ' k=' + view['compressor_param'].astype(int).astype(str)\n",
    "view.loc[df['compressor'] == 'none', 'method'] = df.loc[df['compressor'] == 'none', 'compressor'].replace(c_names)\n",
    "view.loc[df['compressor'] == 'thinning', 'method'] = df.loc[df['compressor'] == 'thinning', 'compressor'].replace(c_names) + ' k=' + view.loc[df['compressor'] == 'thinning', 'compressor_param'].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc = 0\n",
    "mem_sizes = view['mem_size_mb'].unique()\n",
    "\n",
    "for this_mem_size in mem_sizes:\n",
    "    cur_max = view.loc[view['mem_size_mb'] == this_mem_size, 'final_acc'].max()\n",
    "    if cur_max > acc:\n",
    "        acc = cur_max\n",
    "    view = view.drop(\n",
    "        view[\n",
    "            (view['mem_size_mb'] == this_mem_size) & (view['final_acc'] < acc)\n",
    "        ].index\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.graph_objects as go\n",
    "\n",
    "fig = px.scatter(\n",
    "    view.loc[(view['compressor'] == 'quantization local') | (view['compressor'] == 'quantization transfer')],\n",
    "    x='mem_size_mb',\n",
    "    y='final_acc',\n",
    "    color=np.log10(view.loc[(view['compressor'] == 'quantization local') | (view['compressor'] == 'quantization transfer'), 'compressor_param']),\n",
    "    symbol='compressor',\n",
    "    log_x=True,\n",
    "    hover_data={\n",
    "        'mem_size': True,\n",
    "        'encoder': True\n",
    "    },\n",
    "    template=science_template,\n",
    "    labels={\n",
    "        'mem_size': 'Number of Memory Slots',\n",
    "        'final_acc': 'Accuracy',\n",
    "        'mem_size_mb': 'Total Storage Comsumption [MiB]',\n",
    "        'encoder_name': 'Encoder',\n",
    "        'compressor_name': 'Compression Strategy',\n",
    "        'compressor': 'Compressor',\n",
    "        'fcae': 'Fully Connected Autoencoder',\n",
    "    },\n",
    "    color_continuous_scale='Agsunset'\n",
    ")\n",
    "\n",
    "fig.add_trace(\n",
    "    go.Scatter(\n",
    "        x=view.loc[(view['compressor'] == 'thinning'), 'mem_size_mb'],\n",
    "        y=view.loc[(view['compressor'] == 'thinning'), 'final_acc'],\n",
    "        mode='markers',\n",
    "        marker_color='black',\n",
    "        marker_symbol='x',\n",
    "        name='Thinning (k=0.5)'\n",
    "    )\n",
    ")\n",
    "fig.add_trace(\n",
    "    go.Scatter(\n",
    "        x=view.loc[(view['compressor'] == 'none'), 'mem_size_mb'],\n",
    "        y=view.loc[(view['compressor'] == 'none'), 'final_acc'],\n",
    "        mode='markers',\n",
    "        marker_color='black',\n",
    "        marker_symbol='cross',\n",
    "        name='GDumb'\n",
    "    )\n",
    ")\n",
    "\n",
    "fig.update_layout({'legend_title_text': ''})\n",
    "fig.update(layout_coloraxis_showscale=False)\n",
    "fig.update_traces(\n",
    "    marker={\n",
    "        'size': 8,\n",
    "    },\n",
    ")\n",
    "fig.update_yaxes(range=[0, 0.5])\n",
    "config = {\n",
    "    'displaylogo': False,\n",
    "    'toImageButtonOptions': {\n",
    "        'format': 'svg', # one of png, svg, jpeg, webp\n",
    "    }\n",
    "}\n",
    "\n",
    "fig.show(config=config, renderer='browser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "view.loc[(view['compressor'] != 'quantization local') & (view['compressor'] != 'quantization transfer')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.6 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
