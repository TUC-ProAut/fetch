{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CIFAR10 fixed number of memory slots\n",
    "\n",
    "Produces Plots with with compression-factor vs accuracy and fices number of memory slots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "N_SLOTS = 10000\n",
    "BACKBONE_BLOCK = 3\n",
    "SEED = 1\n",
    "outfile = Path('..', 'scripts', 'cifar10_splitR_compression_compf.sh').resolve()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiments = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Base Case"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoders = ['none', 'cutr']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for encoder in encoders:\n",
    "        l =  [\"python3 src/main.py\",\n",
    "            \"--dataset\", \"CIFAR10\",\n",
    "            \"--num_classes_per_task\", \"2\",\n",
    "            \"--num_tasks\", \"5\",\n",
    "            \"--seed\", str(SEED),\n",
    "            \"--memory_size\", str(N_SLOTS),\n",
    "            \"--num_passes\", \"128\",\n",
    "            \"--sampler\", \"greedy_sampler\",\n",
    "            \"--compressor\", \"none\",\n",
    "            \"--backbone\", \"resnet\",\n",
    "            ]\n",
    "        if encoder == 'cutr':\n",
    "            n = f\"cifar10_m{N_SLOTS}_cutr{BACKBONE_BLOCK}_splitr{BACKBONE_BLOCK}__s{SEED}\"\n",
    "            x = [\n",
    "                \"--encoder\", \"cutr\",\n",
    "                \"--encoding_block\", str(BACKBONE_BLOCK),\n",
    "                \"--backbone_block\", str(BACKBONE_BLOCK),\n",
    "                \"--exp_name\", n,\n",
    "            ]\n",
    "        else:\n",
    "            n = f\"cifar10_m{N_SLOTS}_splitr{BACKBONE_BLOCK}__s{SEED}\"\n",
    "            x = [\n",
    "                \"--encoder\", \"none\",\n",
    "                \"--exp_name\", n,\n",
    "            ]\n",
    "        l = l + x\n",
    "        experiments.append(\" \".join(l))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Quantization Compression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_states_list = [2, 4, 8, 16, 32]\n",
    "encoders = ['cutr', 'none']\n",
    "strategies = ['local', 'tiny_imagenet_transfer']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for n_states in n_states_list:\n",
    "    for encoder in encoders:\n",
    "        for strategy in strategies:\n",
    "            l =  [\"python3 src/main.py\",\n",
    "                \"--dataset\", \"CIFAR10\",\n",
    "                \"--num_classes_per_task\", \"2\",\n",
    "                \"--num_tasks\", \"5\",\n",
    "                \"--seed\", str(SEED),\n",
    "                \"--memory_size\", str(N_SLOTS),\n",
    "                \"--num_passes\", \"128\",\n",
    "                \"--sampler\", \"greedy_sampler\",\n",
    "                \"--compressor\", \"quantization\",\n",
    "                \"--strategy\", strategy,\n",
    "                \"--n_states\", str(n_states),\n",
    "                \"--backbone\", \"resnet\",\n",
    "                ]\n",
    "            if encoder == 'cutr':\n",
    "                n = f\"cifar10_m{N_SLOTS}_cutr{BACKBONE_BLOCK}_quantization_{strategy}_{n_states}_splitr{BACKBONE_BLOCK}__s{SEED}\"\n",
    "                x = [\n",
    "                    \"--encoder\", \"cutr\",\n",
    "                    \"--encoding_block\", str(BACKBONE_BLOCK),\n",
    "                    \"--backbone_block\", str(BACKBONE_BLOCK),\n",
    "                    \"--exp_name\", n,\n",
    "                ]\n",
    "            else:\n",
    "                n = f\"cifar10_m{N_SLOTS}__quantization_{strategy}_{n_states}_splitr{BACKBONE_BLOCK}__s{SEED}\"\n",
    "                x = [\n",
    "                    \"--encoder\", \"none\",\n",
    "                    \"--exp_name\", n,\n",
    "                ]\n",
    "            l = l + x\n",
    "            experiments.append(\" \".join(l))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Thinning Compression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compression_factors = [0.5, 0.8, 0.9, 0.95]\n",
    "encoders = ['cutr', 'none']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for compression_factor in compression_factors:\n",
    "    for encoder in encoders:\n",
    "            l =  [\"python3 src/main.py\",\n",
    "                \"--dataset\", \"CIFAR10\",\n",
    "                \"--num_classes_per_task\", \"2\",\n",
    "                \"--num_tasks\", \"5\",\n",
    "                \"--seed\", str(SEED),\n",
    "                \"--memory_size\", str(N_SLOTS),\n",
    "                \"--num_passes\", \"128\",\n",
    "                \"--sampler\", \"greedy_sampler\",\n",
    "                \"--compressor\", \"thinning\",\n",
    "                \"--compression_factor\", str(compression_factor),\n",
    "                \"--backbone\", \"resnet\",\n",
    "                ]\n",
    "            if encoder == 'cutr':\n",
    "                n = f\"cifar10_m{N_SLOTS}_cutr{BACKBONE_BLOCK}_thinning{compression_factor}_splitr{BACKBONE_BLOCK}__s{SEED}\"\n",
    "                x = [\n",
    "                    \"--encoder\", \"cutr\",\n",
    "                    \"--encoding_block\", str(BACKBONE_BLOCK),\n",
    "                    \"--backbone_block\", str(BACKBONE_BLOCK),\n",
    "                    \"--exp_name\", n,\n",
    "                ]\n",
    "            else:\n",
    "                n = f\"cifar10_m{N_SLOTS}_thinning{compression_factor}_splitr{BACKBONE_BLOCK}__s{SEED}\"\n",
    "                x = [\n",
    "                    \"--encoder\", \"none\",\n",
    "                    \"--exp_name\", n,\n",
    "                ]\n",
    "            l = l + x\n",
    "            experiments.append(\" \".join(l))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Autoencoder Compression (conv Autoencoder)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Because we cannot apply pooling after CutR-Compression we dont use the Encoder in tis Case"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "latent_sizes = [1, 2, 4, 8, 16]\n",
    "encoders = ['cutr', 'none']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for latent_size in latent_sizes:\n",
    "    n = f\"cifar10_m{N_SLOTS}_autoencoder{latent_size}_splitr{BACKBONE_BLOCK}__s{SEED}\"\n",
    "    l =  [\"python3 src/main.py\",\n",
    "        \"--dataset\", \"CIFAR10\",\n",
    "        \"--num_classes_per_task\", \"2\",\n",
    "        \"--num_tasks\", \"5\",\n",
    "        \"--seed\", str(SEED),\n",
    "        \"--memory_size\", str(N_SLOTS),\n",
    "        \"--num_passes\", \"128\",\n",
    "        \"--sampler\", \"greedy_sampler\",\n",
    "        \"--compressor\", \"autoencoder\",\n",
    "        \"--latent_channels\", str(latent_size),\n",
    "        \"--backbone\", \"resnet\",\n",
    "        \"--encoder\", \"none\",\n",
    "        \"--exp_name\", n,\n",
    "    ]\n",
    "    experiments.append(\" \".join(l))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fully Connected Autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bottleneck_sizes = [2, 4, 8, 16, 32, 64]\n",
    "encoders = ['cutr', 'none']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for bottleneck_size in bottleneck_sizes:\n",
    "    l =  [\"python3 src/main.py\",\n",
    "        \"--dataset\", \"CIFAR10\",\n",
    "        \"--num_classes_per_task\", \"2\",\n",
    "        \"--num_tasks\", \"5\",\n",
    "        \"--seed\", str(SEED),\n",
    "        \"--memory_size\", str(N_SLOTS),\n",
    "        \"--num_passes\", \"128\",\n",
    "        \"--sampler\", \"greedy_sampler\",\n",
    "        \"--compressor\", \"fcae\",\n",
    "        \"--bottleneck_neurons\", str(bottleneck_size)\n",
    "    ]\n",
    "\n",
    "    n_no_enc = f\"cifar10_m{N_SLOTS}_fcae{bottleneck_size}_resnet__s{SEED}\"\n",
    "    n_enc = f\"cifar10_m{N_SLOTS}_cutr{BACKBONE_BLOCK}_fcae{bottleneck_size}_resnet__s{SEED}\"\n",
    "\n",
    "    l_no_enc = l + [\n",
    "        \"--encoder\", \"none\",\n",
    "        \"--backbone\", \"resnet\",\n",
    "        \"--exp_name\", n_no_enc\n",
    "    ]\n",
    "    l_enc = l + [\n",
    "        \"--encoder\", \"cutr\",\n",
    "        \"--encoding_block\", str(BACKBONE_BLOCK),\n",
    "        \"--backbone\", \"resnet\",\n",
    "        \"--backbone_block\", str(BACKBONE_BLOCK),\n",
    "        \"--exp_name\", n_enc        \n",
    "    ]\n",
    "\n",
    "    experiments.append(' '.join(l_no_enc))\n",
    "    experiments.append(' '.join(l_enc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Write output file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if outfile.exists():\n",
    "    inp = input(f\"output file {outfile} already exists. Overwrite [y/ N]?\")\n",
    "\n",
    "    if not (inp == 'y' or inp == 'Y'):\n",
    "        raise FileExistsError(f'{outfile} exists, nothing has been overwritten') \n",
    "\n",
    "with open(outfile, 'w') as f:\n",
    "    f.write('\\n'.join(experiments))\n",
    "    print('saved!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "logs_dir = Path('/home/marwei/code/Archived_Logs/cifar10_compression_cutr_compf/')\n",
    "\n",
    "dd = []\n",
    "for this_dir in logs_dir.glob('*'):\n",
    "    try:\n",
    "        with open(Path(this_dir, 'checkpoint.log').resolve()) as f:\n",
    "            loglines = f.readlines()\n",
    "\n",
    "        final_acc = float(re.findall(r\"Acc: \\[(.*?)\\]\", loglines[-1])[0])\n",
    "        encoder = re.findall(r\"encoder=\\'(.*?)\\'\", loglines[0])[0]\n",
    "        compressor = re.findall(r\"compressor=\\'(.*?)\\'\", loglines[0])[0]\n",
    "        \n",
    "        if compressor == 'none':\n",
    "            compressor_name = 'none'\n",
    "            compressor_param = None\n",
    "        elif compressor == 'thinning':\n",
    "            compressor_name = 'Thinning'\n",
    "            compressor_param = float(re.findall(r\"compression_factor=(.*?)\\,\", loglines[0])[0])\n",
    "        elif compressor == 'autoencoder' or compressor == 'convae':\n",
    "            compressor_name = 'Convolutional Autoencoder'\n",
    "            compressor_param = int(re.findall(r\"latent_channels=(\\d+)\", loglines[0])[0])\n",
    "        elif compressor == 'fcae':\n",
    "            compressor_name = 'Fully Connected Autoencoder'\n",
    "            compressor_param = int(re.findall(r\"bottleneck_neurons=(\\d+)\", loglines[0])[0])\n",
    "        elif compressor == 'quantization':\n",
    "            strategy = re.findall(r\"strategy=\\'(.*?)\\'\", loglines[0])[0]\n",
    "            if strategy == 'tiny_imagenet_transfer':\n",
    "                compressor_name = 'Quantization (transfer)'\n",
    "            elif strategy == 'local':\n",
    "                compressor_name = 'Quantization (local)'\n",
    "            else:\n",
    "                raise ValueError(f'Unknown Quantization strategy: {strategy}')\n",
    "            compressor_param = int(re.findall(r\"n_states=(\\d+)\", loglines[0])[0])\n",
    "        else:\n",
    "            raise ValueError(f'Unknown Compressor: {compressor}')\n",
    "        \n",
    "        dd.append({\n",
    "            'final_acc': final_acc,\n",
    "            'encoder': encoder,\n",
    "            'compressor': compressor_name,\n",
    "            'param': compressor_param\n",
    "        })\n",
    "    except IndexError:\n",
    "        print(this_dir.stem)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame.from_records(dd).sort_values(['compressor', 'param'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.compressor.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "from plot_utils import science_template\n",
    "\n",
    "df['legend'] = df['encoder']\n",
    "df.loc[df['legend']=='none', 'legend'] = 'No Encoding'\n",
    "df.loc[df['legend']=='cutr', 'legend'] = 'CutR18(3)'\n",
    "view = df.loc[df.compressor != 'none']\n",
    "\n",
    "fig = px.line(\n",
    "    view,\n",
    "    x='param',\n",
    "    y='final_acc',\n",
    "    color='legend',\n",
    "    facet_col='compressor',\n",
    "    template=science_template,\n",
    "    markers=True,\n",
    "    labels={\n",
    "        'final_acc': 'Accuracy',\n",
    "        'param': 'k',\n",
    "        'encoder': 'Encoder',\n",
    "    },\n",
    "    category_orders={\n",
    "        'compressor': ['Thinning', 'Quantization (local)', 'Quantization (transfer)', 'Convolutional Autoencoder', 'Fully Connected Autoencoder']\n",
    "    }\n",
    ")\n",
    "fig.for_each_annotation(lambda a: a.update(text=a.text.split(\"=\")[-1]))\n",
    "fig.update_xaxes(matches=None, rangemode=\"tozero\")\n",
    "fig.update_yaxes(rangemode=\"tozero\")\n",
    "fig.update_layout(legend={'title_text':''})\n",
    "\n",
    "# add baseline-lines\n",
    "y_gdumb = df.loc[(df['encoder']=='none') & (df['compressor'] == 'none'), 'final_acc'].item()\n",
    "y_cutr3 = df.loc[(df['encoder']=='cutr') & (df['compressor'] == 'none'), 'final_acc'].item()\n",
    "fig.add_hline(y=y_gdumb,\n",
    "              line_dash=\"solid\",\n",
    "              line_width=1,\n",
    "              annotation_text=\"\",\n",
    "              annotation_position=\"top right\")\n",
    "fig.add_hline(y=y_cutr3,\n",
    "              line_dash=\"dot\",\n",
    "              line_width=1,\n",
    "              annotation_text=\"\",\n",
    "              annotation_position=\"bottom right\")\n",
    "fig.add_hline(y=0.1,\n",
    "              line_dash=\"dash\",\n",
    "              line_width=1,\n",
    "              annotation_text=\"\",\n",
    "              annotation_position=\"bottom right\")\n",
    "\n",
    "# add invisible data so the baseline-lines appear in the legend\n",
    "fig.add_traces(\n",
    "    [\n",
    "        go.Scatter(\n",
    "            x=[fig.data[0].x[0]],\n",
    "            y=[fig.data[0].y[0]], \n",
    "            showlegend=True,\n",
    "            name='GDumb',\n",
    "            mode='lines',\n",
    "            line_dash='solid',\n",
    "            line_color='black',\n",
    "            line_width=1\n",
    "        ),\n",
    "        go.Scatter(\n",
    "            x=[fig.data[0].x[0]],\n",
    "            y=[fig.data[0].y[0]], \n",
    "            showlegend=True,\n",
    "            name='CutR18(3) without compression',\n",
    "            mode='lines',\n",
    "            line_dash='dot',\n",
    "            line_color='black',\n",
    "            line_width=1\n",
    "        ),\n",
    "        go.Scatter(\n",
    "            x=[fig.data[0].x[0]],\n",
    "            y=[fig.data[0].y[0]], \n",
    "            showlegend=True,\n",
    "            name='random guessing',\n",
    "            mode='lines',\n",
    "            line_dash='dash',\n",
    "            line_color='black',\n",
    "            line_width=1\n",
    "        ),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {\n",
    "    'displaylogo': False,\n",
    "    'toImageButtonOptions': {\n",
    "        'format': 'svg', # one of png, svg, jpeg, webp\n",
    "        'filename': 'plot',\n",
    "        'height': 300,\n",
    "        'width': 1300,\n",
    "        'scale': 1 # Multiply title/legend/axis/canvas sizes by this factor\n",
    "    }\n",
    "}\n",
    "\n",
    "fig.show(renderer='browser', config=config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.10 ('venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "5435a56038887d20f31a7cdbcd79e06dedb0db1cd9c4a9f678003c5d01d40c11"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
