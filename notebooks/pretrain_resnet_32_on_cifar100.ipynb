{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pathlib\n",
    "import os\n",
    "import random\n",
    "import time\n",
    "\n",
    "import torch\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.nn.init as init\n",
    "import torchvision\n",
    "from torchvision.datasets import CIFAR100\n",
    "\n",
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def _weights_init(m):\n",
    "    \"\"\"He initialization\"\"\"\n",
    "    classname = m.__class__.__name__\n",
    "    #print(classname)\n",
    "    if isinstance(m, nn.Linear) or isinstance(m, nn.Conv2d):\n",
    "        init.kaiming_normal_(m.weight)\n",
    "\n",
    "\n",
    "class LambdaLayer(nn.Module):\n",
    "    def __init__(self, lambd):\n",
    "        super(LambdaLayer, self).__init__()\n",
    "        self.lambd = lambd\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.lambd(x)\n",
    "\n",
    "\n",
    "class BasicBlock(nn.Module):\n",
    "    expansion = 1\n",
    "\n",
    "    def __init__(self, in_planes, planes, stride=1, option='A'):\n",
    "        super(BasicBlock, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(in_planes, planes, kernel_size=3, stride=stride, padding=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(planes)\n",
    "        self.conv2 = nn.Conv2d(planes, planes, kernel_size=3, stride=1, padding=1, bias=False)\n",
    "        self.bn2 = nn.BatchNorm2d(planes)\n",
    "\n",
    "        self.shortcut = nn.Sequential()\n",
    "        if stride != 1 or in_planes != planes:\n",
    "            if option == 'A':\n",
    "                \"\"\"\n",
    "                For CIFAR10 ResNet paper uses option A.\n",
    "                \"\"\"\n",
    "                self.shortcut = LambdaLayer(lambda x:\n",
    "                                            F.pad(x[:, :, ::2, ::2], (0, 0, 0, 0, planes//4, planes//4), \"constant\", 0))\n",
    "            elif option == 'B':\n",
    "                self.shortcut = nn.Sequential(\n",
    "                     nn.Conv2d(in_planes, self.expansion * planes, kernel_size=1, stride=stride, bias=False),\n",
    "                     nn.BatchNorm2d(self.expansion * planes)\n",
    "                )\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = F.relu(self.bn1(self.conv1(x)))\n",
    "        out = self.bn2(self.conv2(out))\n",
    "        out += self.shortcut(x)\n",
    "        out = F.relu(out)\n",
    "        return out\n",
    "\n",
    "\n",
    "class Cutr32(nn.Module):\n",
    "    def __init__(self, batch_size):\n",
    "        super().__init__()\n",
    "        block = BasicBlock\n",
    "        num_classes = 100\n",
    "        self.in_planes = 16\n",
    "\n",
    "        self.conv1 = nn.Conv2d(3, 16, kernel_size=3, stride=1, padding=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(16)\n",
    "        self.layer1 = self._make_layer(block, 16, 5, stride=1)\n",
    "        self.layer2 = self._make_layer(block, 32, 5, stride=2)\n",
    "        self.layer3 = self._make_layer(block, 64, 5, stride=2)\n",
    "        self.linear = nn.Linear(64, num_classes)\n",
    "\n",
    "        self.apply(_weights_init)\n",
    "    \n",
    "        \n",
    "\n",
    "    def _make_layer(self, block, planes, num_blocks, stride):\n",
    "        strides = [stride] + [1]*(num_blocks-1)\n",
    "        layers = []\n",
    "        for stride in strides:\n",
    "            layers.append(block(self.in_planes, planes, stride))\n",
    "            self.in_planes = planes * block.expansion\n",
    "\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = F.relu(self.bn1(self.conv1(x)))\n",
    "        out = self.layer1(out)\n",
    "        out = self.layer2(out)\n",
    "        out = self.layer3(out)\n",
    "        out = F.avg_pool2d(out, out.size()[3])\n",
    "        out = out.view(out.size(0), -1)\n",
    "        out = self.linear(out)\n",
    "        return out\n",
    "\n",
    "\n",
    "\n",
    "def seed_everything(seed):\n",
    "    '''\n",
    "    Fixes the class-to-task assignments and most other sources of randomness, except CUDA training aspects.\n",
    "    '''\n",
    "    # Avoid all sorts of randomness for better replication\n",
    "    random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    np.random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    if torch.cuda.is_available():\n",
    "        torch.backends.cudnn.benchmark = True # An exemption for speed :P\n",
    "\n",
    "\n",
    "def rand_bbox(size, lam):\n",
    "    W = size[2]\n",
    "    H = size[3]\n",
    "    cut_rat = np.sqrt(1. - lam)\n",
    "    cut_w = int(W * cut_rat)\n",
    "    cut_h = int(H * cut_rat)\n",
    "\n",
    "    # uniform\n",
    "    cx = np.random.randint(W)\n",
    "    cy = np.random.randint(H)\n",
    "\n",
    "    bbx1 = np.clip(cx - cut_w // 2, 0, W)\n",
    "    bby1 = np.clip(cy - cut_h // 2, 0, H)\n",
    "    bbx2 = np.clip(cx + cut_w // 2, 0, W)\n",
    "    bby2 = np.clip(cy + cut_h // 2, 0, H)\n",
    "\n",
    "    return bbx1, bby1, bbx2, bby2\n",
    "\n",
    "\n",
    "def cutmix_data(x, y, alpha=1.0, cutmix_prob=0.5):\n",
    "    assert(alpha > 0)\n",
    "    # generate mixed sample\n",
    "    lam = np.random.beta(alpha, alpha)\n",
    "\n",
    "    batch_size = x.size()[0]\n",
    "    index = torch.randperm(batch_size)\n",
    "\n",
    "    if torch.cuda.is_available():\n",
    "        index = index.cuda()\n",
    "\n",
    "    y_a, y_b = y, y[index]\n",
    "    bbx1, bby1, bbx2, bby2 = rand_bbox(x.size(), lam)\n",
    "    x[:, :, bbx1:bbx2, bby1:bby2] = x[index, :, bbx1:bbx2, bby1:bby2]\n",
    "\n",
    "    # adjust lambda to exactly match pixel ratio\n",
    "    lam = 1 - ((bbx2 - bbx1) * (bby2 - bby1) / (x.size()[-1] * x.size()[-2]))\n",
    "    return x, y_a, y_b, lam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cutmix_prob = 0.5\n",
    "encoding_block = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 512\n",
    "DEVICE = 'cuda'\n",
    "DATA_DIR = pathlib.Path('.')\n",
    "BATCH_SIZE = 256\n",
    "pretraining_classes = range(50)\n",
    "seed_everything(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_transforms = torchvision.transforms.Compose([\n",
    "    torchvision.transforms.ToTensor(),\n",
    "    torchvision.transforms.Normalize((0.5071, 0.4867, 0.4408), (0.2675, 0.2565, 0.2761))\n",
    "])\n",
    "\n",
    "test_transforms = torchvision.transforms.Compose([\n",
    "    torchvision.transforms.ToTensor(),\n",
    "    torchvision.transforms.Normalize((0.5071, 0.4867, 0.4408),(0.2675, 0.2565, 0.2761))\n",
    "])\n",
    "\n",
    "\n",
    "trainset_full = CIFAR100(\n",
    "    train=True,\n",
    "    transform=train_transforms,\n",
    "    root=DATA_DIR,\n",
    "    download=True\n",
    ")\n",
    "train_subset_idxs = [i for i in range(len(trainset_full)) if trainset_full.targets[i] in pretraining_classes]\n",
    "trainset = torch.utils.data.Subset(trainset_full, train_subset_idxs)\n",
    "\n",
    "testset_full = CIFAR100(\n",
    "    train=False,\n",
    "    transform=test_transforms,\n",
    "    root=DATA_DIR,\n",
    "    download=True\n",
    ")\n",
    "test_subset_idxs = [i for i in range(len(testset_full)) if testset_full.targets[i] in pretraining_classes]\n",
    "testset = torch.utils.data.Subset(testset_full, test_subset_idxs)\n",
    "\n",
    "trainloader = DataLoader(\n",
    "    dataset=trainset,\n",
    "    shuffle=True,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    num_workers=4,\n",
    ")\n",
    "testloader = DataLoader(\n",
    "    dataset=testset,\n",
    "    shuffle=False,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    num_workers=4,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Cutr32(encoding_block).to(DEVICE)\n",
    "\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(\n",
    "    model.parameters(),\n",
    "    lr=0.01,\n",
    "    momentum=0.9,\n",
    "    weight_decay=1e-4,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_model(model, dataloader, criterion, device):\n",
    "    with torch.no_grad():\n",
    "        running_loss = 0\n",
    "        running_acc = 0\n",
    "        for data, target in dataloader:\n",
    "            data = data.to(device)\n",
    "            target = target.to(device)\n",
    "            output = model(data)\n",
    "            loss = criterion(output, target)\n",
    "\n",
    "            prob = torch.nn.functional.softmax(output, dim=1)\n",
    "            pred = torch.argmax(prob, dim=1)\n",
    "            corr = torch.eq(pred, target)\n",
    "            acc = (corr*1.0).mean()\n",
    "\n",
    "            running_acc += acc.item()\n",
    "            running_loss += loss.item()\n",
    "\n",
    "    return (\n",
    "        running_acc/len(dataloader),\n",
    "        running_loss/len(dataloader),\n",
    "    )\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train the model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for data, target in trainloader:\n",
    "    assert (target<50).all().item()\n",
    "for data, target in testloader:\n",
    "    assert (target<50).all().item()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "print('starting testing')\n",
    "model.eval()\n",
    "tstart = time.time()\n",
    "acc, loss = test_model(\n",
    "    model=model,\n",
    "    dataloader=testloader,\n",
    "    criterion=criterion,\n",
    "    device=DEVICE\n",
    ")\n",
    "testtimes = [time.time()-tstart]\n",
    "testlosses = [loss]\n",
    "testaccs = [acc]\n",
    "trainlosses = [loss]\n",
    "trainaccs = [0]\n",
    "traintimes = [0]\n",
    "checkpoints = []\n",
    "best_acc = 0\n",
    "print(f\"epoch {0}\\t testloss {testlosses[-1]:.4f} \\f testacc {testaccs[-1]:.4f}\\t time {testtimes[-1]:.0f} s\")\n",
    "\n",
    "# training\n",
    "for epoch in range(EPOCHS):\n",
    "    running_loss = 0\n",
    "    running_acc = 0\n",
    "    tstart = time.time()\n",
    "    model.train()\n",
    "    for data, target in trainloader:\n",
    "        data = data.to(DEVICE)\n",
    "        target = target.to(DEVICE)\n",
    "\n",
    "        do_cutmix =  np.random.rand(1) < cutmix_prob\n",
    "        if do_cutmix:\n",
    "            data, labels_a, labels_b, lam = cutmix_data(x=data, y=target, alpha=1)\n",
    "            \n",
    "\n",
    "        # output = model(embedding)\n",
    "        output = model(data)\n",
    "        \n",
    "        if do_cutmix:\n",
    "            loss = lam * criterion(output, labels_a) + (1 - lam) * criterion(output, labels_b)\n",
    "        else:\n",
    "            loss = criterion(output, target)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        prob = torch.nn.functional.softmax(output, dim=1)\n",
    "        pred = torch.argmax(prob, dim=1)\n",
    "        corr = torch.eq(pred, target)\n",
    "        acc = (corr*1.0).mean()\n",
    "        running_acc += acc.item()\n",
    "        running_loss += loss.item()\n",
    "\n",
    "    traintimes.append(time.time() - tstart)\n",
    "    trainlosses.append(running_loss / len(trainloader))\n",
    "    trainaccs.append(running_acc / len(trainloader))\n",
    "\n",
    "    print(f\"epoch {epoch+1}\\t trainloss {trainlosses[-1]:.4f} \\f trainacc {trainaccs[-1]:.4f}\\t time {traintimes[-1]:.0f} s\")\n",
    "\n",
    "    # testing\n",
    "    model.eval()\n",
    "    running_loss = 0\n",
    "    running_acc = 0\n",
    "    tstart = time.time()\n",
    "    acc, loss = test_model(\n",
    "        model=model,\n",
    "        dataloader=testloader,\n",
    "        criterion=criterion,\n",
    "        device=DEVICE\n",
    "    )\n",
    "    testtimes.append(time.time()-tstart)\n",
    "    testlosses.append(loss)\n",
    "    testaccs.append(acc)\n",
    "\n",
    "    if acc > best_acc:\n",
    "        path = f\"resnet32_cifar100_classes0to49_e{epoch+1}.pt\"\n",
    "        torch.save(model.state_dict(), path)\n",
    "        checkpoints.append(epoch+1)\n",
    "        best_acc = acc\n",
    "        print(f\"saved checkpoint: {path}\")\n",
    "\n",
    "    print(f\"epoch {epoch+1}\\t testloss {testlosses[-1]:.4f} \\t testacc {testaccs[-1]:.4f}\\t time {testtimes[-1]:.0f} s\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig, (ax1, ax2) = plt.subplots(nrows=2, ncols=1, figsize=(8, 8))\n",
    "\n",
    "ax1.plot(list(range(EPOCHS+1)), trainlosses, label='train')\n",
    "ax1.plot(list(range(EPOCHS+1)), testlosses, label='test')\n",
    "ax1.legend()\n",
    "ax1.set_title('Loss')\n",
    "ax2.plot(list(range(EPOCHS+1)), trainaccs, label='train')\n",
    "ax2.plot(list(range(EPOCHS+1)), testaccs, label='test')\n",
    "ax2.legend()\n",
    "ax2.set_title('Accuracy')\n",
    "fig.savefig('lc.svg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "encodedgdumb",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
